{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "840eb463-f138-4dd8-b3b1-130c877407df",
   "metadata": {},
   "source": [
    "# **RDDs with PySpark**\n",
    "\n",
    "## **Start Coding with PySpark**\n",
    "\n",
    "We’ll be working with data about students applying for college. We usually use PySpark for extremely large datasets, but it’s easier to see how functions work when we start with a smaller example.\n",
    "\n",
    "The data is a list of tuples called student_data. Each tuple contains a name, an SAT score out of 1600, a GPA out of 100% (in decimals), and a state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21cabd5e-f420-463b-bd44-d7dac6964a42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c580f2-9ffd-4e52-8ce5-2d8867a00265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 1523, 0.72, 'CA'),\n",
       " ('Jake', 1555, 0.83, 'NY'),\n",
       " ('Cody', 1439, 0.92, 'CA'),\n",
       " ('Lisa', 1442, 0.81, 'FL'),\n",
       " ('Daniel', 1600, 0.88, 'TX'),\n",
       " ('Kelvin', 1382, 0.99, 'FL'),\n",
       " ('Nancy', 1442, 0.74, 'TX'),\n",
       " ('Pavel', 1599, 0.82, 'NY'),\n",
       " ('Josh', 1482, 0.78, 'CA'),\n",
       " ('Cynthia', 1582, 0.94, 'CA')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_data = [(\"Chris\",1523,0.72,\"CA\"),\n",
    "                (\"Jake\", 1555,0.83,\"NY\"),\n",
    "                (\"Cody\", 1439,0.92,\"CA\"),\n",
    "                (\"Lisa\",1442,0.81,\"FL\"),\n",
    "                (\"Daniel\",1600,0.88,\"TX\"),\n",
    "                (\"Kelvin\",1382,0.99,\"FL\"),\n",
    "                (\"Nancy\",1442,0.74,\"TX\"),\n",
    "                (\"Pavel\",1599,0.82,\"NY\"),\n",
    "                (\"Josh\",1482,0.78,\"CA\"),\n",
    "                (\"Cynthia\",1582,0.94,\"CA\")]\n",
    "student_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b861a290-f44b-45bb-93b4-a64622ee6400",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x7facf482d120>\n"
     ]
    }
   ],
   "source": [
    "# start a spark session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "# confirm the session is built\n",
    "print(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dade8ad9-271d-4cb0-801d-9ae7e6273b26",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 1523, 0.72, 'CA'),\n",
       " ('Jake', 1555, 0.83, 'NY'),\n",
       " ('Cody', 1439, 0.92, 'CA'),\n",
       " ('Lisa', 1442, 0.81, 'FL'),\n",
       " ('Daniel', 1600, 0.88, 'TX'),\n",
       " ('Kelvin', 1382, 0.99, 'FL'),\n",
       " ('Nancy', 1442, 0.74, 'TX'),\n",
       " ('Pavel', 1599, 0.82, 'NY'),\n",
       " ('Josh', 1482, 0.78, 'CA'),\n",
       " ('Cynthia', 1582, 0.94, 'CA')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the student_data into a RDD with 5 partitions\n",
    "student_rdd = spark.sparkContext.parallelize(student_data, 5)\n",
    "# confirm the rdd contains the correct data\n",
    "student_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "071e7f69-e56b-4c1c-bd8f-648a283fc2d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of partitions\n",
    "student_rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc726a6-5e46-43d1-b751-6ae6bf0c4bf9",
   "metadata": {},
   "source": [
    "## **Transformations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3224fee6-1521-4fc0-9440-c8623d52bdb5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 1523, 72.0, 'CA'),\n",
       " ('Jake', 1555, 83.0, 'NY'),\n",
       " ('Cody', 1439, 92.0, 'CA'),\n",
       " ('Lisa', 1442, 81.0, 'FL'),\n",
       " ('Daniel', 1600, 88.0, 'TX'),\n",
       " ('Kelvin', 1382, 99.0, 'FL'),\n",
       " ('Nancy', 1442, 74.0, 'TX'),\n",
       " ('Pavel', 1599, 82.0, 'NY'),\n",
       " ('Josh', 1482, 78.0, 'CA'),\n",
       " ('Cynthia', 1582, 94.0, 'CA')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert the third column from decimals to whole numbers (multiply by 100) and keep the other variables\n",
    "rdd_transformation = student_rdd.map(lambda x: (x[0], x[1], x[2]*100, x[3]))\n",
    "# confirm transformation is correct\n",
    "rdd_transformation.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0294d80e-aad1-4264-bdc0-fa99b04af22f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jake', 1555, 83.0, 'NY'),\n",
       " ('Cody', 1439, 92.0, 'CA'),\n",
       " ('Lisa', 1442, 81.0, 'FL'),\n",
       " ('Daniel', 1600, 88.0, 'TX'),\n",
       " ('Kelvin', 1382, 99.0, 'FL'),\n",
       " ('Pavel', 1599, 82.0, 'NY'),\n",
       " ('Cynthia', 1582, 94.0, 'CA')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter to include just the rows with grades above 80\n",
    "rdd_filtered = rdd_transformation.filter(lambda x: x[2] > 80)\n",
    "# confirm transformation is correct\n",
    "rdd_filtered.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6670d52-8992-4d6e-9793-d78db03f4e1c",
   "metadata": {},
   "source": [
    "## **Actions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9addcc25-d0c3-487f-951d-b933ef43a880",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Jake', 1555, 83.0, 'NY'),\n",
       " ('Cody', 1439, 92.0, 'CA'),\n",
       " ('Lisa', 1442, 81.0, 'FL'),\n",
       " ('Daniel', 1600, 88.0, 'TX'),\n",
       " ('Kelvin', 1382, 99.0, 'FL')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the first five elements\n",
    "rdd_transformation.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "03a92b01-f60a-4b85-a4df-9f57c69bfa2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "843.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum the grades\n",
    "sum_gpa = rdd_transformation.map(lambda x: x[2]).reduce(lambda x,y: x+y)\n",
    "sum_gpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee9ca48-4f8b-4c20-afb9-1c4927ee6569",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the average grade\n",
    "sum_gpa / rdd_transformation.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77831865-da94-4a18-ac00-cc0295d01bbd",
   "metadata": {},
   "source": [
    "## **Associative and Commutative Properties**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35727981-3c9d-4301-916b-95f26a49150a",
   "metadata": {},
   "source": [
    "Only operations both commutative and associative can be applied with `reduce()`, but let's see this in practice.\n",
    "\n",
    "Also, the very handy transformation `glom()` can be used to print how how the data is being partitioned and the results of the sum and division operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af6355c9-f442-4189-9e4f-8586f2bd48e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition:  [[1, 2, 3, 4, 5]]\n",
      "addition:  15\n",
      "partition:  [[1, 2], [3, 4, 5]]\n",
      "addition:  15\n",
      "partition:  [[1], [2, 3], [4, 5]]\n",
      "addition:  15\n",
      "partition:  [[1], [2], [3], [4, 5]]\n",
      "addition:  15\n"
     ]
    }
   ],
   "source": [
    "# notice how the sum never changes as the number of partitions grows\n",
    "data = [1,2,3,4,5]\n",
    "for i in range(1,5):\n",
    "    rdd = spark.sparkContext.parallelize(data, i)\n",
    "    print('partition: ', rdd.glom().collect())\n",
    "    print('addition: ', rdd.reduce(lambda a,b: a+b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b07cd420-e58e-459d-bc60-b6d14f66441c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "partition:  [[1, 2, 3, 4, 5]]\n",
      "division:  0.008333333333333333\n",
      "partition:  [[1, 2], [3, 4, 5]]\n",
      "division:  3.3333333333333335\n",
      "partition:  [[1], [2, 3], [4, 5]]\n",
      "division:  1.875\n",
      "partition:  [[1], [2], [3], [4, 5]]\n",
      "division:  0.20833333333333331\n"
     ]
    }
   ],
   "source": [
    "# notice how the final result changes as the number of partitions grows\n",
    "for i in range(1,5):\n",
    "    rdd = spark.sparkContext.parallelize(data, i)\n",
    "    print('partition: ', rdd.glom().collect())\n",
    "    print('division: ', rdd.reduce(lambda a,b: a/b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af587a-e31a-4629-b38e-fcb9b7166f8f",
   "metadata": {},
   "source": [
    "## **Broadcast Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37f1d14a-0826-439d-b195-8374ebd396eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.broadcast.Broadcast"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this dictionary contains the names and abbreviations for the four states\n",
    "states = {\"NY\":\"New York\", \"CA\":\"California\", \"TX\":\"Texas\", \"FL\":\"Florida\"}\n",
    "\n",
    "# broadcast the states dictionary to spark cluster\n",
    "broadcastStates = spark.sparkContext.broadcast(states)\n",
    "# confirm type\n",
    "type(broadcastStates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26bd213e-88e3-46a6-b6c5-dc3142541404",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Chris', 1523, 72.0, 'California'),\n",
       " ('Jake', 1555, 83.0, 'New York'),\n",
       " ('Cody', 1439, 92.0, 'California'),\n",
       " ('Lisa', 1442, 81.0, 'Florida'),\n",
       " ('Daniel', 1600, 88.0, 'Texas'),\n",
       " ('Kelvin', 1382, 99.0, 'Florida'),\n",
       " ('Nancy', 1442, 74.0, 'Texas'),\n",
       " ('Pavel', 1599, 82.0, 'New York'),\n",
       " ('Josh', 1482, 78.0, 'California'),\n",
       " ('Cynthia', 1582, 94.0, 'California')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# map the abbreviations to their full names\n",
    "rdd_broadcast = rdd_transformation.map(lambda x: (x[0], x[1], x[2], broadcastStates.value[x[3]]))\n",
    "# confirm transformation is correct\n",
    "rdd_broadcast.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bfee2bc-f8e4-4121-8cb3-97db86bb3ce2",
   "metadata": {},
   "source": [
    "## **Accumulator Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f260fc3-7cef-458f-9215-28cde406d360",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.accumulators.Accumulator"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create an accumulator variable that starts at 0\n",
    "sat_1500 = spark.sparkContext.accumulator(0)\n",
    "# confirm type\n",
    "type(sat_1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d91b3bad-6c28-44e8-88a5-ee860bc86199",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function count_high_sat_score at 0x7facd93ea050>\n"
     ]
    }
   ],
   "source": [
    "# create a function that increments the accumulator by 1 whenever it encounters a score over 1500\n",
    "def count_high_sat_score(score):\n",
    "    if score > 1500: sat_1500.add(1)\n",
    "# confirm type\n",
    "print(count_high_sat_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ecc266-4b64-4de4-bc6e-022cdae608c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049f38fe-1bef-4fc0-b319-ff5082427633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef99741-c6c6-4a59-b9bc-cf9e2e51a858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7260892d-aa08-421e-9b89-5549ba0d2cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844713d2-87ed-4163-a7a9-e4e1ec0d4bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop the session\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
