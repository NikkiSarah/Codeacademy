{"cells":[{"source":"# **Machine Learning Pipelines**\n\nIn this lesson we’re going to learn how to turn a machine learning (ML) workflow to a pipeline using `scikit-learn`. A ML pipeline is a modular sequence of objects that codifies and automates a ML workflow to make it efficient, reproducible and generalizable. While the process of building pipelines is not singular, there are some tools that are universally used to do this. The most accessible of these is `scikit-learn`'s `Pipeline` object which allows us to chain together the different steps that go into a ML workflow.\n\nTurning a workflow into a pipeline has many other advantages too. Pipelines provide consistency — the same steps will always be applied in the same order under the same conditions. They also are very concise and can streamline your code. The `Pipeline` object within `scikit-learn` has consistent methods to use the many other estimators and transformers we have already covered in our ML curriculum. It is usually the starting point for a Machine Learning Engineer before turning to more sophisticated tools for scaling pipelines (such as PySpark, etc) and we will delve deeper into it in this lesson\n\nWhat can go into a pipeline? For any of the intermediate steps, it must have both the `.fit` and `.transform` methods. This includes preprocessing, imputation, feature selection and dimensionality reduction. The final step must have the `.fit` method. Examples of tasks we’ve seen already that could benefit from a pipeline include:\n- scaling data then applying principal component analysis\n- filling in missing values then fitting a regression model\n- one-hot-encoding categorical variables and scaling numerical variables.","metadata":{"id":"bA5ajAmk7XH6"},"cell_type":"markdown","id":"f165d227-38f2-4b31-a763-1fa27cf28cdc"},{"source":"## Data Cleaning - Numeric\n\nTo introduce pipelines, let’s look at a common set of data cleaning/EDA tasks — dealing with missing values and scaling numeric variables. We’re going to convert an existing code base that performs these tasks to more concise code that uses `scikit-learn`'s `Pipeline`.","metadata":{},"cell_type":"markdown","id":"35f3cfea-4d6a-40ac-9ba1-4d0c80d08100"},{"source":"import numpy as np\nimport pandas as pd\nfrom sklearn import datasets\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder","metadata":{},"cell_type":"code","id":"96294b22-f6ef-4563-9461-784102bbb098","execution_count":28,"outputs":[]},{"source":"columns = [\"sex\",\"length\",\"diam\",\"height\",\"whole\",\"shucked\",\"viscera\",\"shell\",\"age\"]\ndf = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\", names=columns)\n\ny = df.age\nX = df.drop(columns=['age'])\nnum_cols = X.select_dtypes(include=np.number).columns\ncat_cols = X.select_dtypes(include=['object']).columns\n#create some missing values\nfor i in range(1000):\n    X.loc[np.random.choice(X.index),np.random.choice(X.columns)] = np.nan\n    \nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.25) ","metadata":{},"cell_type":"code","id":"dfb1cd13-c155-4ed6-8643-838aac8b8cd9","execution_count":2,"outputs":[]},{"source":"## not using a pipeline\n\nX_train_num = X_train[num_cols]\n# fill missing values with mean on numeric features only\nX_train_fill_missing = X_train_num.fillna(X_train_num.mean())\n# fit standard scaler on X_train_fill_missing\nscale = StandardScaler().fit(X_train_fill_missing)\n# scale data after filling in missing values\nX_train_fill_missing_scale = scale.transform(X_train_fill_missing)\n\n# repeat on the test set \nX_test_fill_missing = X_test[num_cols].fillna(X_train_num.mean())\nX_test_fill_missing_scale = scale.transform(X_test_fill_missing)","metadata":{},"cell_type":"code","id":"72c56edd-7690-46b1-9c01-863503ce142d","execution_count":3,"outputs":[]},{"source":"## using a pipeline\n\n# instantiate a pipeline object\npipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"mean\")), (\"scale\", StandardScaler())])\n\npipeline.fit(X_train[num_cols])\nX_transform = pipeline.transform(X_test[num_cols])\n\n# confirm that X_transform and X_test_fill_missing_scale are the same\narray_diff = np.sum(np.abs(X_test_fill_missing_scale - X_transform))\narray_diff","metadata":{},"cell_type":"code","id":"03556284-2cfc-4e31-a12e-a2cc967f5b33","execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"0.0"},"metadata":{}}]},{"source":"# instantiate a pipeline object\npipeline_median = Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scale\", StandardScaler())])\n\npipeline_median.fit(X_train[num_cols])\nX_transform_median = pipeline_median.transform(X_test[num_cols])\n\n# confirm that X_transform and X_test_fill_missing_scale are different\narray_diff = np.sum(np.abs(X_test_fill_missing_scale - X_transform_median))\narray_diff","metadata":{},"cell_type":"code","id":"4bbec588-a0f1-47a1-b6ec-6ed2a0311670","execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"44.7499993017456"},"metadata":{}}]},{"source":"# confirm that the results of the pipelines are indeed different\narray_diff = np.sum(np.abs(X_transform - X_transform_median))\narray_diff","metadata":{},"cell_type":"code","id":"c2064883-53b4-4582-b068-fb08fd62e8b9","execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"44.7499993017456"},"metadata":{}}]},{"source":"## Data Cleaning - Categorical\n\nWe’re now going to implement a task similar to the previous exercise with `pipeline.Pipeline()`, but with categorical variables now. Specifically we’ll be dealing with missing values in categorical data and one-hot-encoding categorical variables. We will convert an existing codebase to a pipeline like in the previous exercise.","metadata":{},"cell_type":"markdown","id":"3df812de-f5b3-4cd7-b5cb-24edda155efa"},{"source":"## not using a pipeline\n\nX_train_cat = X_train[cat_cols]\n# fill missing values with mode on categorical features only\nX_train_fill_missing = X_train_cat.fillna(X_train_cat.mode().values[0][0])\n# one-hot-encode categorical features in X_train_fill_missing\nohe = OneHotEncoder(sparse=False, drop='first').fit(X_train_fill_missing)\nX_train_fill_missing_ohe = ohe.transform(X_train_fill_missing)\n\n# repeat on the test set\nX_test_fill_missing = X_test[cat_cols].fillna(X_train_cat.mode().values[0][0])\nX_test_fill_missing_ohe = ohe.transform(X_test_fill_missing)","metadata":{},"cell_type":"code","id":"832db1e0-9ca8-49b3-8a9a-3cec116e708e","execution_count":7,"outputs":[]},{"source":"## using a pipeline\n\npipeline = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", OneHotEncoder(drop='first', sparse=False))])\n\npipeline.fit(X_train[cat_cols])\nX_transform = pipeline.transform(X_test[cat_cols])\n\n# confirm that X_transform and X_test_fill_missing_ohe are the same\ncheck_arrays = np.array_equal(X_transform, X_test_fill_missing_ohe)\ncheck_arrays","metadata":{},"cell_type":"code","id":"8516702a-594c-452c-97ff-c2ef72d5ca16","execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"source":"## Column Transformer\n\nOften times, you may not want to simply apply every function to all columns. If our columns are of different types, we may only want to apply certain parts of the pipeline to a subset of columns. This is what we saw in the two previous exercises. One set of transformations are applied to numeric columns and another set to the categorical ones. We can use `scikit-learn`'s `ColumnTransformer` as one way of combining these processes together.\n\n`ColumnTransformer` takes in a list of tuples of the form `(name, pipeline, columns)`:\n\n```\nexample_column_transformer = ColumnTransformer(\n    transformers=[ (\"name_1\", pipeline_1, columns_1),\n                   (\"name_2\", pipeline_2, columns_2)])\n```\n\nThe transformer can be anything with a `.fit` and `.transform` method like we used previously (like `SimpleImputer` or `StandardScaler`), but can also itself be a pipeline, as we will use in the exercise.","metadata":{},"cell_type":"markdown","id":"13f36f0b-69bb-49de-a215-6ce65263b6f1"},{"source":"# create separate pipelines for the categorical and numeric features\nnum_vals = Pipeline([(\"imputer\", SimpleImputer(strategy='mean')), (\"scale\", StandardScaler())])\ncat_vals = Pipeline([(\"imputer\", SimpleImputer(strategy=\"most_frequent\")), (\"ohe\", OneHotEncoder(sparse=False, drop='first'))])\n\n# create a column transformer\npreprocess = ColumnTransformer(transformers=[(\"num_preprocess\", num_vals, num_cols),\n                                             (\"cat_preprocess\", cat_vals, cat_cols)]\n                              )\n\n\n# fit to the training and test data\npreprocess.fit(X_train)\nx_transform = preprocess.transform(X_test)","metadata":{},"cell_type":"code","id":"77264ba0-aa3a-4b34-908d-269b2f125980","execution_count":9,"outputs":[]},{"source":"## Adding a Model\n\nNow that we have all the preprocessing done and coded succinctly using `ColumnTransformer` and `Pipeline`, we can add a model. We will take the result at the end of the previous exercise, and now create a final pipeline with the `ColumnTransformer` as the first step, and a `LinearRegression()` model as the second step.\n\nBy adding a model to the final step, the last step no longer has a `.transform` method. This is the only step in a pipeline that can be a non-transformer. But now the final step also has a `.predict` method, which can be called on the entire pipeline! Additionally the `.score()` method, which estimates the default prediction score on any `scikit-learn` model can also be used to evaluate the performance of the pipeline.","metadata":{},"cell_type":"markdown","id":"3db9113e-0a7b-4b42-8cb7-768fb3c3256a"},{"source":"# create a pipeline including the column transformer and a linear regression\npipeline = Pipeline([(\"preprocess\", preprocess), (\"regr\", LinearRegression())])\n\n# fit the pipeline on the training data and predict on the test data\npipeline.fit(X_train, y_train)\ny_pred = pipeline.predict(X_test)\n\n# use the score method\npipeline_score = pipeline.score(X_test, y_test)\npipeline_score","metadata":{},"cell_type":"code","id":"8b44f4eb-2189-4b8a-ae6f-45d2d90d37c9","execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"0.49892357249092656"},"metadata":{}}]},{"source":"# compare this against R2 (the default performance metric for linear regression)\nr2_score = r2_score(y_test, y_pred)\nprint(r2_score)","metadata":{},"cell_type":"code","id":"08f43165-e76b-4af8-89fe-fe9042dfb45b","execution_count":14,"outputs":[{"name":"stdout","text":"0.49892357249092656\n","output_type":"stream"}]},{"source":"## Hyperparameter Tuning\n\nWhat now? Well, we can tune some of the parameters of the model by applying a grid search over a range of hyperparameter values.\n\nA linear regression model has very few hyperparameters and here we’ll be using the hyperparameter that pertains to whether we include an intercept or not. As we’ve aseen, the pipeline created in the previous exercise is an estimator and we can call the `.fit()` and `.predict()` methods on it. So in fact, the whole pipeline can be passed as an estimator for `GridSearchCV`. This will then refit the pipeline for each combination of parameter values in the grid and each fold in the cross-validation split.\n\nThat’s a lot – but the code is again very short. One last thing to keep in mind while referencing hyperparameters in a pipeline is the following: any hyperparameter can be called using `pipeline_step_name + '__' + hyperparameter`. For example, `regr__fit_intercept` corresponds to a pipeline step named “regr” and the hyperparameter “fit_intercept”.","metadata":{},"cell_type":"markdown","id":"e99b0ed6-f1a4-4088-aeb2-ca40189e8d49"},{"source":"# simple parameter grid with and without the intercept\nparam_grid = {\n    \"regr__fit_intercept\": [True,False]\n}\n\n# define a GridSearchCV object\ngs = GridSearchCV(pipeline, param_grid, scoring='neg_mean_squared_error', cv=5)\n\n# fit to the training data\ngs.fit(X_train, y_train)\nbest_score = gs.best_score_\nbest_score","metadata":{},"cell_type":"code","id":"10393281-710a-40c9-9b98-d3ab674fbadc","execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"-5.423115734444834"},"metadata":{}}]},{"source":"best_params = gs.best_params_\nbest_params","metadata":{},"cell_type":"code","id":"959bcbda-15c7-405f-9575-0f0f7b56e6d5","execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"{'regr__fit_intercept': True}"},"metadata":{}}]},{"source":"## Final Pipeline\n\nNow that we are getting the hang of pipelines, we’re going take things up a notch. We will now be searching over different types of models, each having their own sets of hyperparameters! In the original pipeline, we defined regr to be an instance of `LinearRegression()`. Then in defining the parameter grid to search over, we used the dictionary `{\"regr__fit_intercept\": [True,False]}` to define the values of the fit_intercept term. We can equivalently do this by passing both the estimator AND parameters in a single dictionary as\n```\n{'regr': [LinearRegression()], \"regr__fit_intercept\": [True,False]}\n```\nWe can add more models to it as follows. Suppose we wanted to add a Ridge regression model and also perform hyperparamter tuning using `GridSearchCV` to find the best regularization parameter `alpha`, we would add it to previous dictionary to create an array of dictionaries as follows:\n```\nsearch_space = [{'regr': [LinearRegression()], 'regr__fit_intercept': [True,False]},\n                {'regr':[Ridge()], 'regr__alpha': [0,0.1,1,10,100]}\n```\n\nThe goal of this process is to find the best estimator for our dataset and problem in the most efficient manner possible. The pipeline module allows us to do exactly that! In a couple of lines of code, we’re able to preprocess the data and search an entire model and hyperparameter space. The final step is to access the pipeline elements to draw out the information about which estimator and hyperparameter set gets us the best score. We do this by using the `.next_steps` method by using the strings we’ve used in the dictionary. For instance, the regression model can be access using the string 'regr' from the dictionary as follows:\n\n- Get the best estimator using `GridSearchCV`'s `.best_estimator_` method\n- Use `.named_steps['regr'].get_params()` on the best estimator to get its hyperparameters!","metadata":{},"cell_type":"markdown","id":"8d73fefe-7707-4ecd-a1e8-0f0a7446b5f6"},{"source":"# define the linear regression search space\nsearch_space = [{'regr': [LinearRegression()], 'regr__fit_intercept': [True,False]},\n                {'regr': [Ridge()], 'regr__alpha': [0,0.1,1,10,100]},\n                {'regr': [Lasso()], 'regr__alpha': [0,0.1,1,10,100]}]\n\n# initialise a grid search on 'search space'\ngs = GridSearchCV(pipeline, search_space, scoring='neg_mean_squared_error', cv=5)\n\n# fit to the training data\ngs.fit(X_train, y_train)\n# find the best pipeline\nbest_pipeline = gs.best_estimator_\nbest_pipeline","metadata":{},"cell_type":"code","id":"56d742e9-8892-46c5-a80a-aae58e586672","execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Pipeline(steps=[('preprocess',\n                 ColumnTransformer(transformers=[('num_preprocess',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer()),\n                                                                  ('scale',\n                                                                   StandardScaler())]),\n                                                  Index(['length', 'diam', 'height', 'whole', 'shucked', 'viscera', 'shell'], dtype='object')),\n                                                 ('cat_preprocess',\n                                                  Pipeline(steps=[('imputer',\n                                                                   SimpleImputer(strategy='most_frequent')),\n                                                                  ('ohe',\n                                                                   OneHotEncoder(drop='first',\n                                                                                 sparse=False))]),\n                                                  Index(['sex'], dtype='object'))])),\n                ('regr', Ridge(alpha=1))])","text/html":"<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;num_preprocess&#x27;,\n                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                                   SimpleImputer()),\n                                                                  (&#x27;scale&#x27;,\n                                                                   StandardScaler())]),\n                                                  Index([&#x27;length&#x27;, &#x27;diam&#x27;, &#x27;height&#x27;, &#x27;whole&#x27;, &#x27;shucked&#x27;, &#x27;viscera&#x27;, &#x27;shell&#x27;], dtype=&#x27;object&#x27;)),\n                                                 (&#x27;cat_preprocess&#x27;,\n                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n                                                                  (&#x27;ohe&#x27;,\n                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n                                                                                 sparse=False))]),\n                                                  Index([&#x27;sex&#x27;], dtype=&#x27;object&#x27;))])),\n                (&#x27;regr&#x27;, Ridge(alpha=1))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocess&#x27;,\n                 ColumnTransformer(transformers=[(&#x27;num_preprocess&#x27;,\n                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                                   SimpleImputer()),\n                                                                  (&#x27;scale&#x27;,\n                                                                   StandardScaler())]),\n                                                  Index([&#x27;length&#x27;, &#x27;diam&#x27;, &#x27;height&#x27;, &#x27;whole&#x27;, &#x27;shucked&#x27;, &#x27;viscera&#x27;, &#x27;shell&#x27;], dtype=&#x27;object&#x27;)),\n                                                 (&#x27;cat_preprocess&#x27;,\n                                                  Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                                   SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n                                                                  (&#x27;ohe&#x27;,\n                                                                   OneHotEncoder(drop=&#x27;first&#x27;,\n                                                                                 sparse=False))]),\n                                                  Index([&#x27;sex&#x27;], dtype=&#x27;object&#x27;))])),\n                (&#x27;regr&#x27;, Ridge(alpha=1))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocess: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;num_preprocess&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;, SimpleImputer()),\n                                                 (&#x27;scale&#x27;, StandardScaler())]),\n                                 Index([&#x27;length&#x27;, &#x27;diam&#x27;, &#x27;height&#x27;, &#x27;whole&#x27;, &#x27;shucked&#x27;, &#x27;viscera&#x27;, &#x27;shell&#x27;], dtype=&#x27;object&#x27;)),\n                                (&#x27;cat_preprocess&#x27;,\n                                 Pipeline(steps=[(&#x27;imputer&#x27;,\n                                                  SimpleImputer(strategy=&#x27;most_frequent&#x27;)),\n                                                 (&#x27;ohe&#x27;,\n                                                  OneHotEncoder(drop=&#x27;first&#x27;,\n                                                                sparse=False))]),\n                                 Index([&#x27;sex&#x27;], dtype=&#x27;object&#x27;))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">num_preprocess</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;length&#x27;, &#x27;diam&#x27;, &#x27;height&#x27;, &#x27;whole&#x27;, &#x27;shucked&#x27;, &#x27;viscera&#x27;, &#x27;shell&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">cat_preprocess</label><div class=\"sk-toggleable__content\"><pre>Index([&#x27;sex&#x27;], dtype=&#x27;object&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(strategy=&#x27;most_frequent&#x27;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;, sparse=False)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div></div></div>"},"metadata":{}}]},{"source":"# locate the best regression model\nbest_regression_model = best_pipeline.named_steps['regr']\nbest_regression_model","metadata":{},"cell_type":"code","id":"7a5ed5db-6698-4af9-971d-3d9087a446e2","execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"Ridge(alpha=1)","text/html":"<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=1)</pre></div></div></div></div></div>"},"metadata":{}}]},{"source":"# determine the best hyperparameters of the best model\nbest_model_hyperparameters = best_regression_model.get_params()\nbest_model_hyperparameters","metadata":{},"cell_type":"code","id":"7f291012-b479-4090-909b-0b5f29c37c12","execution_count":25,"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"{'alpha': 1,\n 'copy_X': True,\n 'fit_intercept': True,\n 'max_iter': None,\n 'normalize': 'deprecated',\n 'positive': False,\n 'random_state': None,\n 'solver': 'auto',\n 'tol': 0.001}"},"metadata":{}}]},{"source":"# access the hyperparameters of the categorical preprocessing step\ncat_preprocess_hyperparameters = best_pipeline.named_steps['preprocess'].named_transformers_['cat_preprocess'].named_steps['imputer'].get_params()\ncat_preprocess_hyperparameters","metadata":{},"cell_type":"code","id":"e83f785f-e204-427b-8d99-63b6bc2481c6","execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"{'add_indicator': False,\n 'copy': True,\n 'fill_value': None,\n 'missing_values': nan,\n 'strategy': 'most_frequent',\n 'verbose': 'deprecated'}"},"metadata":{}}]},{"source":"## Writing Custom Classes\n\nWhile scikit-learn contains many existing transformers and classes that can be used in pipelines, you may need at some point to create your own. This is simpler than you may think, as a step in the pipeline needs to have only a few methods implemented. If it is an intermediate step, it will need fit and transform methods. We will implement all of this in the exercise below!\n\nHere are some of the major takeaways on building pipelines in `scikit-learn`:\n\n- Pipelines help make concise, reproducible, code by combining steps of transformers and/or a final estimator.\n- Intermediate steps of a pipeline must have both the `.fit()` and `.transform()` methods. This includes preprocessing, imputation, feature selection, dimension reduction.\n- The final step of a pipeline must have the `.fit()` method – this can include a transformer or an estimator/model.\n- If the pipeline is meant to only transform your data by combining preprocessing and data cleaning steps, then each step in the pipeline will be a transformer. If your pipeline will also include a model (a final estimation or prediction step), then the last step must be an estimator.\n- Once the steps of a pipeline are defined, it can be used like an other transformer/estimator by calling fit, transform, and/or predict methods. Similarly, it can be used in place of an estimator in a hyperparameter grid search.","metadata":{},"cell_type":"markdown","id":"191ecd63-aa94-482d-8517-40f104afef71"},{"source":"# the class `MyImputer` replicates the `SimpleImputer` using the mean strategy\nclass MyImputer(BaseEstimator, TransformerMixin): \n    def __init__(self):\n        return None\n    \n    def fit(self, X, y = None):\n        self.means = np.mean(X, axis=0)    # calculate the mean of each column\n        return self\n    \n    def transform(self, X, y = None):\n        #transform method fills in missing values with means using pandas\n        return X.fillna(self.means)\n    \n# create a new pipeline using the custom class and StandardScaler on the second\nnew_pipeline = Pipeline([(\"myImputer\", MyImputer()), (\"scale\", StandardScaler())])\n\n# fit the pipeline on the training data and apply to the test data\nnew_pipeline.fit(X_train[num_cols])\nX_transform = new_pipeline.transform(X_test[num_cols])\n\n# verify the results are the same as x_test_fill_missing_scale\ncheck_arrays = np.array_equal(X_transform, X_test_fill_missing_scale)\nprint(check_arrays)","metadata":{},"cell_type":"code","id":"2f019a38-3230-4cc3-9e8c-fffe744f463f","execution_count":29,"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}]},{"source":"","metadata":{},"cell_type":"code","id":"e623181e-9fe5-4d8d-b3fe-74a92d34d55a","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}